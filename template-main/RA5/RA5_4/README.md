# ğŸ“Š K3s + K9s: Despliegue y ValidaciÃ³n en Entorno Kubernetes (RA5.4)

## ğŸ“– IntroducciÃ³n

En esta prÃ¡ctica se ha desarrollado una arquitectura de despliegue y administraciÃ³n de contenedores utilizando **K3s**, una distribuciÃ³n ligera de Kubernetes, y **K9s**, una herramienta de terminal para gestionar clÃºsteres Kubernetes.

La actividad estÃ¡ enfocada en la validaciÃ³n del entorno Kubernetes mediante tres enfoques clave:

* ğŸŸ¢ Despliegue inicial en **modo single-node** con un servicio de nginx replicado.
  
* ğŸ”„ Escalado del entorno a un clÃºster **HA (High Availability)**.
  
* ğŸ§± Despliegue a partir de un archivo `docker-compose` convertido a recursos Kubernetes mediante `Kompose`.


## ğŸ“Œ PrÃ¡cticas Implementadas

ğŸ“‚ **Despliegue y GestiÃ³n Kubernetes con K3s + K9s:**

* ğŸ”¹ **Single-node Deployment** â€“ âš™ï¸ InstalaciÃ³n de K3s en modo local, despliegue de nginx y validaciÃ³n con K9s.
  
* ğŸ”¹ **ClÃºster HA** â€“ ğŸ§© InstalaciÃ³n de K3s con `--cluster-init` y configuraciÃ³n para admitir mÃºltiples nodos.
  
* ğŸ”¹ **Kompose + Docker Compose** â€“ ğŸ³ ConversiÃ³n de `docker-compose.yml` a manifiestos Kubernetes y despliegue en K3s.

---

# ğŸ§© 5. Actividades

## ğŸ”¹ 5.1 InstalaciÃ³n y validaciÃ³n de K3s en modo single-node

Este apartado tiene como objetivo crear un clÃºster local de Kubernetes con **K3s** sobre un solo nodo y desplegar un servicio web `nginx` replicado.

### ğŸ›  InstalaciÃ³n de K3s

La instalaciÃ³n se realiza mediante un script oficial:

```bash
curl -sfL https://get.k3s.io | sh -
```

ğŸ“¸ **InstalaciÃ³n del clÃºster K3s en modo single-node:**


![instalacion_k3s](https://github.com/XaviGimReu/PPS-10836126/blob/main/template-main/RA5/RA5_4/assets/1.%20Instalaci%C3%B3n%20k3s.png)

ğŸ›  Se lanza el script oficial de instalaciÃ³n paraconfigurar el nodo maestro.



### ğŸ“¦ Despliegue de nginx con 2 rÃ©plicas

Se define un `Deployment` para lanzar dos rÃ©plicas de nginx. Esto permite validar la capacidad de Kubernetes de manejar cargas replicadas.

ğŸ“„ **Archivo `nginx_deployment.yml`:**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deploy
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
```

ğŸ“¸ **DefiniciÃ³n y despliegue del Deployment de nginx:**
![deploy\_nginx](assets/2.%20ConfiguraciÃ³n%20y%20lanzamient%20de%20nginx.png)
ğŸ“¦ Se define un `Deployment` con 2 rÃ©plicas del contenedor `nginx`.

---

### ğŸ” VerificaciÃ³n de los pods

Se comprueba que las dos rÃ©plicas de nginx estÃ©n en estado `Running`:

```bash
kubectl get pods
```

ğŸ“¸ **ComprobaciÃ³n de que los pods de nginx estÃ¡n corriendo:**
![verificacion\_nginx](assets/3.%20VerificaciÃ³n%20de%20lanzamiento.png)
ğŸ” Se valida visualmente el estado de los pods desplegados.

---

### ğŸ“¥ InstalaciÃ³n y ejecuciÃ³n de K9s

Se utiliza K9s para una visualizaciÃ³n en tiempo real del estado del clÃºster y sus recursos.

```bash
curl -sS https://webinstall.dev/k9s | bash
k9s
```

ğŸ“¸ **InstalaciÃ³n de la herramienta K9s:**
![instalacion\_k9s](assets/4.%20InstalaciÃ³n%20k9s.png)
ğŸ”§ Se descarga e instala la utilidad de administraciÃ³n K9s.

ğŸ“¸ **Vista del clÃºster desde la interfaz de K9s:**
![lanzamiento\_k9s](assets/5.%20Lanzamiento%20k9s.png)
ğŸ–¥ï¸ VisualizaciÃ³n del entorno Kubernetes usando K9s.

---

## ğŸ”¹ 5.2 InstalaciÃ³n y validaciÃ³n de K3s en modo HA

Este apartado busca convertir el clÃºster en un entorno **altamente disponible**, habilitando la opciÃ³n `--cluster-init` para permitir la incorporaciÃ³n de nodos adicionales.

### ğŸ›  InstalaciÃ³n inicial en modo HA

```bash
curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="server --cluster-init" sh -
```

ğŸ“¸ **Inicio del clÃºster K3s en modo HA:**
![instalacion\_ha](assets/6.%20InstalaciÃ³n%20k3s%20\(HA\).png)
ğŸ” Se activa el modo `--cluster-init` para admitir mÃºltiples nodos.

---

### ğŸ”‘ ObtenciÃ³n del token del nodo lÃ­der

Este token es necesario para que los nuevos nodos se unan al clÃºster:

```bash
sudo cat /var/lib/rancher/k3s/server/node-token
```

ğŸ“¸ **Token generado por el nodo principal del clÃºster:**
![token\_ha](assets/7.%20Token%20del%20nodo1.png)
ğŸ” Clave compartida para la autenticaciÃ³n entre nodos.

---

### ğŸŒ SimulaciÃ³n de uniÃ³n de un nuevo nodo

Se documenta el comando de uniÃ³n:

```bash
curl -sfL https://get.k3s.io | \
K3S_URL=https://192.168.1.49:6443 \
K3S_TOKEN=<TOKEN> sh -
```

ğŸ“¸ **SimulaciÃ³n de uniÃ³n de un nodo agente al clÃºster:**
![union\_nodo](assets/8\(0\).%20Union%20otro%20nodo.png)
ğŸ§© Se documenta el comando utilizado para integrar nodos adicionales.

---

### ğŸ“¦ Despliegue del servicio nginx (modo HA)

El mismo manifiesto de despliegue se aplica en el clÃºster HA:

```bash
kubectl apply -f ha_nginx_deployment.yml
```

ğŸ“¸ **AplicaciÃ³n del Deployment en el clÃºster HA:**
![deploy\_ha](assets/8.%20Despliegue%20ha_nginx_deployment.yml.png)
ğŸ“„ Se despliega nginx en alta disponibilidad con 2 rÃ©plicas.

---

## ğŸ”¹ 5.3 Despliegue con docker-compose y validaciÃ³n en K3s

Este apartado valida la integraciÃ³n entre aplicaciones existentes en `docker-compose` y su conversiÃ³n a Kubernetes mediante `Kompose`.

### ğŸ“ Archivo docker-compose

```yaml
version: "3"
services:
  web1:
    image: nginx
  web2:
    image: nginx
  balanceador:
    image: nginx
    ports:
      - "8080:80"
```

ğŸ“¸ **DefiniciÃ³n del stack docker-compose a convertir:**
![compose\_file](assets/9.%20docker-compose.yml.png)
ğŸ“‘ Contiene 2 servicios nginx y un balanceador expuesto en el puerto 8080.

---

### ğŸ” ConversiÃ³n a manifiestos Kubernetes con Kompose

```bash
kompose convert
```

Esto genera los archivos YAML necesarios para cada servicio y su deployment correspondiente.

ğŸ“¸ **ConversiÃ³n automÃ¡tica de docker-compose a Kubernetes:**
![kompose\_convert](assets/10.%20Despliegue%20de%20docker-compose.png)
âš™ï¸ Kompose crea los `Deployment` y `Service` de cada contenedor definido.

---

### ğŸŒ ExposiciÃ³n del balanceador nginx

El archivo `balanceador-service.yaml` se ajusta para exponer el puerto mediante `NodePort`:

```yaml
spec:
  type: NodePort
  ports:
    - port: 80
      targetPort: 80
      nodePort: 30080
```

Se aplica con:

```bash
kubectl apply -f balanceador-service.yaml
```

Y se accede vÃ­a navegador:

```
http://192.168.1.49:30080
```

ğŸ“¸ **Acceso y verificaciÃ³n del balanceador desde navegador:**
![verificacion\_compose](assets/11.%20ComprobaciÃ³n%20del%20despliegue.png)
ğŸŒ Se valida la respuesta HTTP a travÃ©s del puerto expuesto 30080.

---

## âœ… ConclusiÃ³n

Se ha logrado completar de forma satisfactoria el ciclo completo de despliegue en Kubernetes con **K3s**, incluyendo:

* ğŸŸ¢ CreaciÃ³n de clÃºster single-node.
* ğŸ”„ ConversiÃ³n a entorno HA.
* ğŸ³ IntegraciÃ³n de docker-compose en Kubernetes.
* ğŸ–¥ï¸ ValidaciÃ³n visual con `k9s` y pruebas de acceso reales.

Este entorno es Ãºtil como base para arquitecturas mÃ¡s complejas, integraciones con CI/CD y plataformas de monitorizaciÃ³n.

---

## ğŸ“š Referencias

* [https://k3s.io](https://k3s.io)
* [https://k9scli.io](https://k9scli.io)
* [https://kompose.io](https://kompose.io)
* [https://aulasoftwarelibre.github.io/taller-de-docker/dockerfile/#balanceo-de-carga](https://aulasoftwarelibre.github.io/taller-de-docker/dockerfile/#balanceo-de-carga)
